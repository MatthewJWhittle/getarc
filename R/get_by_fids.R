#' Get by FIDs
#'
#' Get a layer by querying the FIDs
#'
#' This function works by checking if the requested return count is less tha the max record count.
#' If so, it doesn't bother with getting the FIDs and just requests the data and returns it.
#' Getting FIDs is a big overhea so this should be avoided where possible.
#' @param endpoint a string defining the enpoint url.
#' It can be generated by the \code{feature_server_endpoint} and \code{map_server_endpoint} functons.
#' See https://developers.arcgis.com/rest/services-reference/get-started-with-the-services-directory.htm
#' @param my_token an access token acquired via \code{get_token}
#' @param query the query to POST
#' @param return_geometry should the geometry be returned or just a table?
#' @param return_n how many features (maximum) should be returned by the query?
#' @param layer_details the layer details returned by the get_layer_details function
#' @param out_fields the fields of the layer to return (character vector)
#' @return a tibble or sf object
#' @importFrom progress progress_bar
#' @importFrom purrr map
#' @importFrom dplyr bind_rows
#' @importFrom utils modifyList
get_by_fids <-
  function(endpoint,
           query,
           my_token,
           return_geometry,
           return_n,
           layer_details,
           out_fields,
           object_ids = NULL) {
    # This function works by checking if the requested return count is less tha the max record count.
    # If so, it doesnn't bother with getting the FIDs and just requests the data and returns it.
    # Getting FIDs is a big overhea so this should be avoided where possible.
    query_url <- paste0(endpoint, "/query")

    # Add the token into the query
    query <-
      utils::modifyList(query, list(token = parse_access_token(my_token)), keep.null = FALSE)

    # Check if the user has requested less rows than the maxrecord count, if so don't initiate
    # getting the FIDs and the where in query and just return the data
    # if ((!is.null(return_n)) && return_n < layer_details$maxRecordCount) {
    data <-
      get_data(
        query_url = query_url,
        query = query,
        return_geometry = return_geometry,
        pb = NULL
      )
    # Print a warning if there are no features returned by the query.
    # Return an empty tibble
    if (nrow(data) == 0) {
      warning("No data matching query, returning an empty tibble")
      return(
        make_empty_tibble(
          field_names = layer_details$fields$name,
          out_fields = out_fields
        )
      )
    }

    # If the number of rows returned is less than the max record count then return the
    # data and don't execute the rest of the function
    # This fails when there is an issue with parsing the jsonby st_read
    # It doesn't always return the max record count even if that is what is returned by the api
    # As a result this will fail
    # This is a temporary fix to get the count which should be returned by the query and
    # Then check whether the data can be returned without acquiring more
    feature_count <-
      get_count(endpoint, query =  query, my_token = my_token)

    if (feature_count < layer_details$maxRecordCount ||
        ((!is.null(return_n)) &&
         return_n < layer_details$maxRecordCount)) {
      return(data)
    }

    # Otherwise, get the FIDs and return the data
    # The FIDs are used for two things: first to determine if any results will be returned by a query;
    # second to get the data by FIDs
    if(is.null(object_ids)){
    object_ids <-
      get_feature_ids(endpoint = endpoint,
                      query = query,
                      my_token = my_token)
    }

    # Check if any FIDs will be returned by the query, if not return an empty tibble avoiding the query
    if (length(object_ids$objectIds) == 0) {
      warning("No data matching query, returning an empty tibble")
      return(
        make_empty_tibble(
          field_names = layer_details$fields$name,
          out_fields = out_fields
        )
      )
    }

    # Work out which IDs have already been downloaded and drop them to avoid downloading
    # data that has already been downloaded
    keep <- c((nrow(data) + 1):length(object_ids$objectIds))
    object_ids$objectIds <- object_ids$objectIds[keep]

    # Then split the vector so it doesn't exceed the max record count
    object_ids_split <-
      split_vector(x = object_ids$objectIds,
                   max_length = layer_details$maxRecordCount)

    querys <-
      purrr::map(object_ids_split,
                 ~ utils::modifyList(
                   query,
                   where_in_query(object_ids$objectIdFieldName, .x, named = TRUE)
                 ), keep.null = FALSE)

    # Define a progress bar
    pb <- progress::progress_bar$new(
      total = length(querys),
      clear = FALSE,
      width = 60,
      format = "  Downloading data [:bar] :percent in :elapsed eta: :eta"
    )

    # Download the data for each query
    data_list <- purrr::map(
      querys,
      ~ get_data(
        query_url = query_url,
        query = .x,
        return_geometry = return_geometry,
        pb = pb
      )
    )

    data_list <- c(list(data), data_list)
    dplyr::bind_rows(data_list)
  }
